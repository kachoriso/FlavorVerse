#!/usr/bin/env python3
"""
FlavorVerse CORS Proxy Server
AI APIã¸ã®CORSå•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼
"""

import http.server
import socketserver
import json
import urllib.request
import urllib.parse
from urllib.error import HTTPError
import os
from http import HTTPStatus

class CORSProxyHandler(http.server.SimpleHTTPRequestHandler):
    def end_headers(self):
        # CORS ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type, Authorization')
        super().end_headers()

    def do_OPTIONS(self):
        # ãƒ—ãƒªãƒ•ãƒ©ã‚¤ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾å¿œ
        self.send_response(HTTPStatus.OK)
        self.end_headers()

    def do_GET(self):
        if self.path == '/api/health':
            # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            self.send_response(HTTPStatus.OK)
            self.send_header('Content-Type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps({"status": "ok", "message": "Proxy server is running"}).encode('utf-8'))
        else:
            super().do_GET()

    def do_POST(self):
        if self.path.startswith('/api/'):
            self.handle_api_request()
        else:
            super().do_POST()

    def handle_api_request(self):
        try:
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’èª­ã¿å–ã‚Š
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length)
            request_data = json.loads(post_data.decode('utf-8'))
            
            # APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’åˆ¤å®š
            if self.path == '/api/gemini':
                response = self.call_gemini_api(request_data)
            elif self.path == '/api/groq':
                response = self.call_groq_api(request_data)
            elif self.path == '/api/cohere':
                response = self.call_cohere_api(request_data)
            else:
                self.send_error(404, "API endpoint not found")
                return
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é€ä¿¡
            self.send_response(HTTPStatus.OK)
            self.send_header('Content-Type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps(response, ensure_ascii=False).encode('utf-8'))
            
        except Exception as e:
            print(f"API Error: {e}")
            self.send_error(500, f"API Error: {str(e)}")


    def call_gemini_api(self, request_data):
        # APIã‚­ãƒ¼ã¯ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ç®¡ç†
        api_key = 'AIzaSyCEGUEEDxUZC2-qO0BpOiK4iiYbpYhA0mc'
        prompt = request_data.get('prompt')
        
        if not prompt:
            raise ValueError("Prompt is required")
        
        # Google Gemini APIå‘¼ã³å‡ºã—ï¼ˆæœ€æ–°ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}"
        headers = {
            'Content-Type': 'application/json'
        }
        
        data = {
            "contents": [{
                "parts": [{
                    "text": f"""ã‚ãªãŸã¯æ—¥æœ¬ã®ãƒ¯ã‚¤ãƒ³å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ¯ã‚¤ãƒ³ã«ã¤ã„ã¦ã€ç¾ã—ãè©©çš„ãªæ—¥æœ¬èªã§ãƒ†ã‚¤ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒãƒ¼ãƒˆã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚

ãƒ¯ã‚¤ãƒ³ã®ç‰¹å¾´: {prompt}

æ¡ä»¶:
- å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„
- 200æ–‡å­—ç¨‹åº¦ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„
- ãƒ¯ã‚¤ãƒ³å°‚é–€ç”¨èªã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- ã‚¨ãƒ¬ã‚¬ãƒ³ãƒˆã§è©©çš„ãªè¡¨ç¾ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„
- ã€Œã“ã®ãƒ¯ã‚¤ãƒ³ã¯ã€ã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„

ãƒ†ã‚¤ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒãƒ¼ãƒˆ:"""
                }]
            }],
            "generationConfig": {
                "temperature": 0.7,
                "maxOutputTokens": 300,
                "topP": 0.8,
                "topK": 40
            }
        }
        
        req = urllib.request.Request(url,
                                   data=json.dumps(data).encode('utf-8'),
                                   headers=headers)
        
        with urllib.request.urlopen(req) as response:
            result = json.loads(response.read().decode('utf-8'))
            
            if 'candidates' in result and len(result['candidates']) > 0:
                content = result['candidates'][0]['content']['parts'][0]['text'].strip()
                # ã€Œã“ã®ãƒ¯ã‚¤ãƒ³ã¯ã€ã§å§‹ã¾ã‚‹ã‚ˆã†ã«èª¿æ•´
                if not content.startswith('ã“ã®ãƒ¯ã‚¤ãƒ³ã¯'):
                    content = f"ã“ã®ãƒ¯ã‚¤ãƒ³ã¯{content}"
                return {
                    "content": content,
                    "provider": "Google Gemini"
                }
            else:
                raise Exception("No candidates in Gemini response")

    def call_groq_api(self, request_data):
        # Groq APIã‚­ãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
        api_key = os.getenv('GROQ_API_KEY', 'YOUR_GROQ_API_KEY')
        prompt = request_data.get('prompt')
        
        if not prompt:
            raise ValueError("Prompt is required")
        
        # Groq APIå‘¼ã³å‡ºã—
        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        data = {
            "model": "llama-3.1-8b-instant",  # ã‚ˆã‚Šè»½é‡ã§åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«
            "messages": [
                {
                    "role": "system",
                    "content": "You are a Japanese wine expert. Write elegant and poetic wine tasting notes in Japanese. Always respond in Japanese only."
                },
                {
                    "role": "user",
                    "content": f"Write a Japanese wine tasting note (about 200 characters) starting with 'ã“ã®ãƒ¯ã‚¤ãƒ³ã¯' for a wine with these characteristics: {prompt}. Use elegant and poetic Japanese expressions."
                }
            ],
            "max_tokens": 300,
            "temperature": 0.7,
            "top_p": 0.9
        }
        
        req = urllib.request.Request(url,
                                   data=json.dumps(data).encode('utf-8'),
                                   headers=headers)
        
        try:
            with urllib.request.urlopen(req) as response:
                result = json.loads(response.read().decode('utf-8'))
        except HTTPError as e:
            error_body = e.read().decode('utf-8')
            print(f"Groq API Error {e.code}: {error_body}")
            raise Exception(f"Groq API Error {e.code}: {error_body}")
            
        if 'choices' in result and len(result['choices']) > 0:
            content = result['choices'][0]['message']['content'].strip()
            
            # ã€Œã“ã®ãƒ¯ã‚¤ãƒ³ã¯ã€ã§å§‹ã¾ã‚‹ã‚ˆã†ã«èª¿æ•´
            if not content.startswith('ã“ã®ãƒ¯ã‚¤ãƒ³ã¯'):
                content = f"ã“ã®ãƒ¯ã‚¤ãƒ³ã¯{content}"
            
            return {
                "content": content,
                "provider": "Groq AI"
            }
        else:
            raise Exception("No choices in Groq response")

    def call_cohere_api(self, request_data):
        # Cohere APIã‚­ãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
        api_key = os.getenv('COHERE_API_KEY', 'YOUR_COHERE_API_KEY')
        prompt = request_data.get('prompt')
        
        if not prompt:
            raise ValueError("Prompt is required")
        
        # Cohere APIå‘¼ã³å‡ºã—
        url = "https://api.cohere.ai/v1/generate"
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            "model": "command-light",  # ç„¡æ–™ãƒ—ãƒ©ãƒ³ã§ä½¿ç”¨å¯èƒ½
            "prompt": f"""Please respond ONLY in Japanese. You are a Japanese wine expert.

{prompt}

ä¸Šè¨˜ã®ãƒ¯ã‚¤ãƒ³ã«ã¤ã„ã¦ã€æ—¥æœ¬èªã§ã‚¨ãƒ¬ã‚¬ãƒ³ãƒˆãªãƒ†ã‚¤ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒãƒ¼ãƒˆã‚’200æ–‡å­—ç¨‹åº¦ã§æ›¸ã„ã¦ãã ã•ã„ã€‚å¿…ãšæ—¥æœ¬èªã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚¤ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒãƒ¼ãƒˆ: ã“ã®ãƒ¯ã‚¤ãƒ³ã¯""",
            "max_tokens": 200,
            "temperature": 0.7,
            "k": 0,
            "stop_sequences": ["English", "english", "In English"],
            "return_likelihoods": "NONE"
        }
        
        req = urllib.request.Request(url,
                                   data=json.dumps(data).encode('utf-8'),
                                   headers=headers)
        
        with urllib.request.urlopen(req) as response:
            result = json.loads(response.read().decode('utf-8'))
            
            if 'generations' in result and len(result['generations']) > 0:
                content = result['generations'][0]['text'].strip()
                # ã€Œã“ã®ãƒ¯ã‚¤ãƒ³ã¯ã€ã§å§‹ã¾ã‚‹ã‚ˆã†ã«èª¿æ•´
                if not content.startswith('ã“ã®ãƒ¯ã‚¤ãƒ³ã¯'):
                    content = f"ã“ã®ãƒ¯ã‚¤ãƒ³ã¯{content}"
                return {
                    "content": content,
                    "provider": "Cohere AI"
                }
            else:
                raise Exception("No generations in Cohere response")

def run_server(port=8003):
    handler = CORSProxyHandler
    # IPv6ã¨IPv4ã®ä¸¡æ–¹ã§ãƒªãƒƒã‚¹ãƒ³ã™ã‚‹ã‚ˆã†ã«è¨­å®š
    httpd = socketserver.TCPServer(("0.0.0.0", port), handler)
    print(f"ğŸš€ FlavorVerse CORS Proxy Server running on http://localhost:{port}")
    print(f"ğŸŒ Server listening on 0.0.0.0:{port} (IPv4)")
    print("ğŸ“¡ AI API calls will be proxied through this server")
    httpd.serve_forever()

if __name__ == "__main__":
    run_server()
